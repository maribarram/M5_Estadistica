{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "896b504c",
   "metadata": {},
   "source": [
    "# Utilización, procesamiento y visualización de grandes volúmenes de datos\n",
    "\n",
    "## Marcela Ibarra Mora\n",
    "## A01231973"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13adb9bf",
   "metadata": {},
   "source": [
    "Dentro de esta entrega se estara utilizado un dataset obtenido de la plataforma Kaggle, este dataset cuenta con información sobre las multas aplicadas dentro de la ciudad de Nueva York detro del perdiodo fiscal de Agosto 2013 a Junio 2014. \n",
    "\n",
    "Primero Inicializamos el entorno de Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b1d794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mc/spark/spark-3.2.2-bin-hadoop3.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Estableciendo variable de entorno\n",
    "import os\n",
    "# import pandas as pd\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-arm64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/mc/spark/spark-3.2.2-bin-hadoop3.2\"\n",
    "\n",
    "#Buscando e inicializando la instalación de Spark\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426cc11e",
   "metadata": {},
   "source": [
    "Se inicializa una sesion de Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c5a59c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/10/31 01:43:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://fox-arm.subnet02281739.vcn02281739.oraclevcn.com:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Entrega 1. Modulo 1.</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0xffff5d412b20>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "       .builder \\\n",
    "       .appName(\"Entrega 1. Modulo 1.\") \\\n",
    "       .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a60ca59",
   "metadata": {},
   "source": [
    "Se importan las librerias a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32ca60a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import desc\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40d15cf",
   "metadata": {},
   "source": [
    "Se importan los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "673de811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.option('header', 'true').csv('../Mar:)/Parking_Violations_Issued_-_Fiscal_Year_2014__August_2013___June_2014_.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a76976a",
   "metadata": {},
   "source": [
    "Seleccionamos las columnas las cuales vamos a utilizar y cambiamos los nombres para no tener conflictos en futuras operaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "308a5447",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(['Vehicle Make','Violation Code','Street Code1','Violation Description'])\n",
    "df = df.withColumnRenamed(\"Vehicle Make\",\"VehicleMake\")\n",
    "df = df.withColumnRenamed(\"Violation Code\",\"ViolationCode\")\n",
    "df = df.withColumnRenamed(\"Street Code1\",\"StreetCode1\")\n",
    "df = df.withColumnRenamed(\"Violation Description\",\"ViolationDesc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46070353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-----------+-------------+\n",
      "|VehicleMake|ViolationCode|StreetCode1|ViolationDesc|\n",
      "+-----------+-------------+-----------+-------------+\n",
      "|       AUDI|           46|      37250|         null|\n",
      "|       FORD|           46|      37290|         null|\n",
      "|      CHEVR|           46|      37030|         null|\n",
      "|       FORD|           46|      37270|         null|\n",
      "|        GMC|           41|      37240|         null|\n",
      "|      DODGE|           14|      37250|         null|\n",
      "|       null|           14|      37250|         null|\n",
      "|       FORD|           24|      63430|         null|\n",
      "|      TOYOT|           24|      63430|         null|\n",
      "|      SUBAR|           24|          0|         null|\n",
      "|      HYUND|           24|          0|         null|\n",
      "|      TOYOT|           24|          0|         null|\n",
      "|       AUDI|           24|          0|         null|\n",
      "|      NISSA|           24|      23230|         null|\n",
      "|      CHEVR|           14|      34190|         null|\n",
      "|      VOLKS|           20|      28930|         null|\n",
      "|      TOYOT|           14|          0|         null|\n",
      "|      SATUR|           20|          0|         null|\n",
      "|        KIA|           14|      73690|         null|\n",
      "|      NISSA|           20|      32030|         null|\n",
      "+-----------+-------------+-----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185deca7",
   "metadata": {},
   "source": [
    "Verificamos el tipo de dato de cada columan y hacemos los cambios pertinentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e43b52c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VehicleMake: string (nullable = true)\n",
      " |-- ViolationCode: string (nullable = true)\n",
      " |-- StreetCode1: string (nullable = true)\n",
      " |-- ViolationDesc: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b032a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"ViolationCode\",df.ViolationCode.cast('int'))\n",
    "df = df.withColumn(\"StreetCode1\",df.StreetCode1.cast('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e26d5b3",
   "metadata": {},
   "source": [
    "Verificamos si tenemos valores nulos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6571758c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:====================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-----------+-------------+\n",
      "|VehicleMake|ViolationCode|StreetCode1|ViolationDesc|\n",
      "+-----------+-------------+-----------+-------------+\n",
      "|      38298|            0|          1|       744783|\n",
      "+-----------+-------------+-----------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,isnan, when, count\n",
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12a4e6e",
   "metadata": {},
   "source": [
    "La columan de VehicleMake cuenta con una gran cantidad de valores nulos por lo tanto lo mejor es cambiarlos por el la marca de autos con mayor frecuencia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eda9b582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:====================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|VehicleMake| count|\n",
      "+-----------+------+\n",
      "|       FORD|732565|\n",
      "|      TOYOT|512799|\n",
      "|      HONDA|471738|\n",
      "|      CHEVR|436035|\n",
      "|      NISSA|379398|\n",
      "|      DODGE|186381|\n",
      "|        GMC|186318|\n",
      "|      ME/BE|176257|\n",
      "|        BMW|159276|\n",
      "|      INTER|156987|\n",
      "|      FRUEH|156452|\n",
      "|       JEEP|123225|\n",
      "|      HYUND|109351|\n",
      "|      LEXUS|105950|\n",
      "|      VOLKS| 95108|\n",
      "|      ACURA| 94209|\n",
      "|      LINCO| 93571|\n",
      "|      CHRYS| 91700|\n",
      "|      MITSU| 77777|\n",
      "|      INFIN| 72781|\n",
      "+-----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#se obtiene la marca con mayor frecuencia, en este caso es FORD\n",
    "df.groupBy(['VehicleMake']).count().sort(desc('count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c247ebb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:====================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-----------+-------------+\n",
      "|VehicleMake|ViolationCode|StreetCode1|ViolationDesc|\n",
      "+-----------+-------------+-----------+-------------+\n",
      "|          0|            0|          1|       744783|\n",
      "+-----------+-------------+-----------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Sustituimos los NaN de la columna VehicleMake por FORD\n",
    "df = df.na.fill('FORD', 'VehicleMake')\n",
    "\n",
    "#volvemos a obtener los NaN \n",
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd37868",
   "metadata": {},
   "source": [
    "Todavia contamos con NaN ahora en las columnas de ViolationDesc y StreetCode1, estos se eliminaran del dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1bf3286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:=============================================>            (7 + 2) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-----------+-------------+\n",
      "|VehicleMake|ViolationCode|StreetCode1|ViolationDesc|\n",
      "+-----------+-------------+-----------+-------------+\n",
      "|          0|            0|          0|            0|\n",
      "+-----------+-------------+-----------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#se eliminan NaN restantes\n",
    "df = df.na.drop()\n",
    "\n",
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "764c5373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-----------+------------------+\n",
      "|VehicleMake|ViolationCode|StreetCode1|     ViolationDesc|\n",
      "+-----------+-------------+-----------+------------------+\n",
      "|      TOYOT|            5|          0|BUS LANE VIOLATION|\n",
      "|       FORD|            5|          0|BUS LANE VIOLATION|\n",
      "|      TOYOT|            5|          0|BUS LANE VIOLATION|\n",
      "|      TOYOT|            5|          0|BUS LANE VIOLATION|\n",
      "|       FORD|            5|          0|BUS LANE VIOLATION|\n",
      "|      TOYOT|            5|          0|BUS LANE VIOLATION|\n",
      "|       FORD|            5|       6110|BUS LANE VIOLATION|\n",
      "|      PONTI|            5|          0|BUS LANE VIOLATION|\n",
      "|      DODGE|            5|          0|BUS LANE VIOLATION|\n",
      "|       FORD|            5|          0|BUS LANE VIOLATION|\n",
      "|      DODGE|            5|          0|BUS LANE VIOLATION|\n",
      "|      TOYOT|            5|          0|BUS LANE VIOLATION|\n",
      "|      TOYOT|            5|          0|BUS LANE VIOLATION|\n",
      "|      TOYOT|            5|       6110|BUS LANE VIOLATION|\n",
      "|      HONDA|            5|          0|BUS LANE VIOLATION|\n",
      "|       FORD|            5|          0|BUS LANE VIOLATION|\n",
      "|      NISSA|            5|          0|BUS LANE VIOLATION|\n",
      "|      CHEVR|            5|          0|BUS LANE VIOLATION|\n",
      "|      TOYOT|            5|          0|BUS LANE VIOLATION|\n",
      "|       FORD|            5|          0|BUS LANE VIOLATION|\n",
      "+-----------+-------------+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283a1fe0",
   "metadata": {},
   "source": [
    "Se guarda este dataset final en un csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee26c0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.repartition(1).write.option(\"header\",True).csv(\"../Mar:)/df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43365576",
   "metadata": {},
   "source": [
    "Ahora se crea un modelo y se hace su entrenamiento.\n",
    "\n",
    "Primero se eliminan las columnas que no nos ayudaran dentro del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e176abbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('VehicleMake','StreetCode1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f0d243",
   "metadata": {},
   "source": [
    "Se separan los datos en un subset de train que contara con el 80% de los datos y otro de test que contara con el 20% de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70d1c391",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a6e127",
   "metadata": {},
   "source": [
    "Creamos un pipeline para poder realizar diferentes funciones, en este caso, se hay un Tokenizer y un Hashing para convertir la columna de ViolationDesc (string) en una entrada prosesable para el modelo. Despues se crea el modelo de Regresión Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05af6f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"ViolationDesc\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.01, labelCol='ViolationCode')\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4957a3e",
   "metadata": {},
   "source": [
    "Se entrena el pipeline con los datos de train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04d3c6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/10/31 01:44:46 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/10/31 01:44:46 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "22/10/31 01:46:14 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "22/10/31 01:46:14 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f68b763",
   "metadata": {},
   "source": [
    "Una vez entrenado el modelo, dentro de un dataset nuevo se realiza una predicción con los datos de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fd02b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mc/spark/spark-3.2.2-bin-hadoop3.2/python/pyspark/sql/dataframe.py:138: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\n",
      "22/10/31 01:59:52 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "predictionsDf = model.transform(test)\n",
    "predictionsDf.registerTempTable('Predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5561b7f",
   "metadata": {},
   "source": [
    "Verificamos que se hizo la predicción al ver las columnas del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78727a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ViolationCode',\n",
       " 'ViolationDesc',\n",
       " 'words',\n",
       " 'features',\n",
       " 'rawPrediction',\n",
       " 'probability',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionsDf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fb9ea0",
   "metadata": {},
   "source": [
    "Desplegamos las predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdb2ec68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+\n",
      "|ViolationCode|prediction|\n",
      "+-------------+----------+\n",
      "|            4|       4.0|\n",
      "|            4|       4.0|\n",
      "|            4|       4.0|\n",
      "|            4|       4.0|\n",
      "|            5|       5.0|\n",
      "|            5|       5.0|\n",
      "|            5|       5.0|\n",
      "|            5|       5.0|\n",
      "|            5|       5.0|\n",
      "|            5|       5.0|\n",
      "|            5|       5.0|\n",
      "|            5|       5.0|\n",
      "|            5|       5.0|\n",
      "|            5|       5.0|\n",
      "|            5|       5.0|\n",
      "|            5|       5.0|\n",
      "|            5|       5.0|\n",
      "|            5|       5.0|\n",
      "|            5|       5.0|\n",
      "|            5|       5.0|\n",
      "+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictionsDf.select('ViolationCode','prediction').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d3e610",
   "metadata": {},
   "source": [
    "Para verificar el performance del modelo, contamos la cantidad de veces que el modelo acerto y lo dividimos con la cantidad registros que tenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a185962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "correctPred = predictionsDf.where(\"\"\"(prediction == ViolationCode)\"\"\").count()\n",
    "numTickets = predictionsDf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e08ddac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 912812 Tickets and there were 912812 successful predictions\n",
      "This is a 100.0% success rate\n"
     ]
    }
   ],
   "source": [
    "print (\"There were\", numTickets, \"Tickets and there were\", correctPred, \"successful predictions\")\n",
    "print (\"This is a\", str((float(correctPred) / float(numTickets)) * 100) + \"%\", \"success rate\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
